{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a093e9ec-92aa-4a45-bd1b-499c648b5f2e",
   "metadata": {},
   "source": [
    "# First Assignment - FINTECH 540 - Machine Learning for FinTech\n",
    "\n",
    "In this assignment, you will gain hands-on experience applying linear models to financial market data. Specifically, you will work with time series prices of the 30 constituents of the *Dow Jones Industrial Average (DJIA)* Index. The dataset covers the period from June $2^{nd}$, 2017, through June $2^{nd}$, 2023. The price series of the ETF associated with the DJIA index is also provided, whose symbol is *DIA*. The dataset is uploaded on Sakai in the same place where you found this notebook.\n",
    "\n",
    "You will deal with three consecutive tasks, so in general, you can only perform a task if you have solved the previous one. You can obtain at most 100 points for this home assignment. The tasks are briefly summarized below, and you can find the relative prompt in each subsection of this notebook:\n",
    "- Build descriptive linear models (CAPM) for all the index constituents (*20 points*).\n",
    "- Select a subset of constituents and fit a predictive linear model to forecast the index value (*40 points*).\n",
    "- Repeat the linear modeling exercise using boostrapped returns (*40 points*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84b16e90-5fc3-44b4-9f02-7481053fa129",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77b438b-9bf5-4cdc-879a-49aa0e6dec56",
   "metadata": {},
   "source": [
    "## Task 1 - Build descriptive linear models (CAPM) for all the index constituents (*20 points*)\n",
    "\n",
    "The Capital Asset Pricing Model (CAPM) is represented as:\n",
    "\n",
    "$$R_i - R_f =   \\beta_i (R_m - R_f) + e_i$$\n",
    "\n",
    "Where:\n",
    "- $R_i$ is the return of the asset or security $i$.\n",
    "- $R_f$ is the risk-free rate, representing the return on a risk-free investment.\n",
    "- $\\beta_i$ is the beta of the asset $i$, which measures its sensitivity to market movements.\n",
    "- $R_m$ is the market portfolio's return (the index).\n",
    "- $e_i$ is the error term or residual representing unexplained variation in the asset's return.\n",
    "\n",
    "The CAPM equation helps estimate the return of an asset based on its risk relative to the market and the risk-free rate. You can calculate the daily risk-free rate by using the following formula.\n",
    "\n",
    "$$ r_{\\text{daily}} = \\left(1 + r_{\\text{annual}}\\right)^{\\frac{1}{365}} - 1 $$\n",
    "\n",
    "Where:\n",
    "- $r_{\\text{daily}}$ is the daily yield. It represents the expected daily return on investment.\n",
    "- $ r_{\\text{annual}} $ is the annual yield. It represents the expected annual return on investment.\n",
    "- The formula assumes daily compounding, meaning the investment's return is calculated daily over a year (365 days). It allows to do the modeling based on daily returns.\n",
    "\n",
    "For this task, you can use an annual yield of *5.482%* per the annualized U.S. 3-month Treasury Bill yield.\n",
    "\n",
    "To solve this part of the homework, you have to:\n",
    "- Compute the daily yield from the annualized provided in the prompt.\n",
    "- Prepared the data to fit the CAPM for each company in the DJIA index described above.\n",
    "- Fit the CAPM for each company and check the estimated sensitivity to market movements.\n",
    "- Select a subset of stocks sensitive to market movements between 0.85 and 1.15. Before including a symbol, ensure the estimated sensitivity is statistically significant. Store the symbols in a Python list before moving to the next task.\n",
    "\n",
    "Before performing the CAPM modeling, remember to split the dataset into a training set and a test set and use only the training set to perform Task 1. Use *2022-01-01* as a cutoff date. Ensure the cutoff date is included in the test set and not in the train set.\n",
    "\n",
    "**Motivation behind the task**\n",
    "\n",
    "Fitting individual CAPM models allows for a detailed assessment of each stock's risk profile. CAPM provides a systematic way to quantify the sensitivity of each stock's returns to market movements, as measured by the beta coefficient. This individual assessment is valuable because different stocks may exhibit varying levels of market sensitivity.\n",
    "\n",
    "Selecting stocks based on their beta values is usually a risk-based approach to portfolio construction. By choosing stocks with higher (lower) beta values, you are essentially selecting those that tend to exhibit greater (lower) price volatility in response to market fluctuations. This can be seen as a deliberate strategy to include riskier (safer) assets in the portfolio.\n",
    "\n",
    "This task will set the basis for selecting a subset of index constituents to be used for a predictive model. \n",
    "\n",
    "**Grading Criteria**\n",
    "\n",
    "- **Data Preparation (10 points)**: Points will be awarded for preparing the data appropriately for the modeling task.\n",
    "\n",
    "- **CAPM Model Fitting (10 points)**: Points will be awarded based on the correctness and completeness of the CAPM models, including accurate significance evaluation and the subset of stock selection based on the beta estimations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd0e79bd-59df-4aa1-aaec-b650e72a8c92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/dows_daily.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33813041-9f34-4538-81c4-44b063e39e86",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DIA</th>\n",
       "      <th>GS.N</th>\n",
       "      <th>NKE.N</th>\n",
       "      <th>CSCO.OQ</th>\n",
       "      <th>JPM.N</th>\n",
       "      <th>DIS.N</th>\n",
       "      <th>INTC.OQ</th>\n",
       "      <th>MRK.N</th>\n",
       "      <th>CVX.N</th>\n",
       "      <th>AXP.N</th>\n",
       "      <th>...</th>\n",
       "      <th>PG.N</th>\n",
       "      <th>IBM.N</th>\n",
       "      <th>MMM.N</th>\n",
       "      <th>AAPL.OQ</th>\n",
       "      <th>WMT.N</th>\n",
       "      <th>CAT.N</th>\n",
       "      <th>AMGN.OQ</th>\n",
       "      <th>V.N</th>\n",
       "      <th>TRV.N</th>\n",
       "      <th>BA.N</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-06-02</th>\n",
       "      <td>211.91</td>\n",
       "      <td>213.31</td>\n",
       "      <td>52.98</td>\n",
       "      <td>31.98</td>\n",
       "      <td>82.64</td>\n",
       "      <td>107.18</td>\n",
       "      <td>36.32</td>\n",
       "      <td>62.427347</td>\n",
       "      <td>103.11</td>\n",
       "      <td>78.49</td>\n",
       "      <td>...</td>\n",
       "      <td>88.59</td>\n",
       "      <td>145.232686</td>\n",
       "      <td>206.70</td>\n",
       "      <td>38.8625</td>\n",
       "      <td>79.62</td>\n",
       "      <td>105.95</td>\n",
       "      <td>159.15</td>\n",
       "      <td>96.15</td>\n",
       "      <td>125.15</td>\n",
       "      <td>190.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-05</th>\n",
       "      <td>211.86</td>\n",
       "      <td>213.99</td>\n",
       "      <td>53.01</td>\n",
       "      <td>31.76</td>\n",
       "      <td>82.79</td>\n",
       "      <td>106.52</td>\n",
       "      <td>36.34</td>\n",
       "      <td>62.045937</td>\n",
       "      <td>103.19</td>\n",
       "      <td>78.97</td>\n",
       "      <td>...</td>\n",
       "      <td>88.74</td>\n",
       "      <td>145.576545</td>\n",
       "      <td>206.22</td>\n",
       "      <td>38.4825</td>\n",
       "      <td>80.26</td>\n",
       "      <td>105.20</td>\n",
       "      <td>160.22</td>\n",
       "      <td>96.55</td>\n",
       "      <td>125.38</td>\n",
       "      <td>188.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-06</th>\n",
       "      <td>211.37</td>\n",
       "      <td>214.53</td>\n",
       "      <td>52.48</td>\n",
       "      <td>31.56</td>\n",
       "      <td>82.96</td>\n",
       "      <td>105.50</td>\n",
       "      <td>36.13</td>\n",
       "      <td>61.664526</td>\n",
       "      <td>104.17</td>\n",
       "      <td>78.85</td>\n",
       "      <td>...</td>\n",
       "      <td>88.80</td>\n",
       "      <td>145.538339</td>\n",
       "      <td>205.41</td>\n",
       "      <td>38.6125</td>\n",
       "      <td>78.93</td>\n",
       "      <td>104.55</td>\n",
       "      <td>159.53</td>\n",
       "      <td>95.79</td>\n",
       "      <td>124.03</td>\n",
       "      <td>186.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-07</th>\n",
       "      <td>211.72</td>\n",
       "      <td>215.78</td>\n",
       "      <td>53.23</td>\n",
       "      <td>31.61</td>\n",
       "      <td>83.91</td>\n",
       "      <td>105.92</td>\n",
       "      <td>36.26</td>\n",
       "      <td>61.082876</td>\n",
       "      <td>103.77</td>\n",
       "      <td>79.81</td>\n",
       "      <td>...</td>\n",
       "      <td>88.77</td>\n",
       "      <td>144.210661</td>\n",
       "      <td>205.01</td>\n",
       "      <td>38.8425</td>\n",
       "      <td>79.15</td>\n",
       "      <td>103.51</td>\n",
       "      <td>161.66</td>\n",
       "      <td>96.09</td>\n",
       "      <td>123.50</td>\n",
       "      <td>188.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-08</th>\n",
       "      <td>211.86</td>\n",
       "      <td>218.76</td>\n",
       "      <td>53.20</td>\n",
       "      <td>31.61</td>\n",
       "      <td>84.95</td>\n",
       "      <td>104.32</td>\n",
       "      <td>36.48</td>\n",
       "      <td>60.262843</td>\n",
       "      <td>104.00</td>\n",
       "      <td>79.95</td>\n",
       "      <td>...</td>\n",
       "      <td>87.85</td>\n",
       "      <td>145.280444</td>\n",
       "      <td>205.94</td>\n",
       "      <td>38.7475</td>\n",
       "      <td>78.93</td>\n",
       "      <td>105.01</td>\n",
       "      <td>162.65</td>\n",
       "      <td>96.09</td>\n",
       "      <td>123.78</td>\n",
       "      <td>189.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-26</th>\n",
       "      <td>330.84</td>\n",
       "      <td>332.01</td>\n",
       "      <td>107.51</td>\n",
       "      <td>49.86</td>\n",
       "      <td>136.94</td>\n",
       "      <td>88.29</td>\n",
       "      <td>29.00</td>\n",
       "      <td>111.070000</td>\n",
       "      <td>154.08</td>\n",
       "      <td>157.24</td>\n",
       "      <td>...</td>\n",
       "      <td>145.40</td>\n",
       "      <td>128.890000</td>\n",
       "      <td>96.94</td>\n",
       "      <td>175.4300</td>\n",
       "      <td>146.42</td>\n",
       "      <td>211.80</td>\n",
       "      <td>216.93</td>\n",
       "      <td>225.01</td>\n",
       "      <td>172.29</td>\n",
       "      <td>203.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-30</th>\n",
       "      <td>330.52</td>\n",
       "      <td>330.83</td>\n",
       "      <td>106.52</td>\n",
       "      <td>50.17</td>\n",
       "      <td>137.46</td>\n",
       "      <td>87.82</td>\n",
       "      <td>29.99</td>\n",
       "      <td>109.170000</td>\n",
       "      <td>153.12</td>\n",
       "      <td>158.01</td>\n",
       "      <td>...</td>\n",
       "      <td>143.18</td>\n",
       "      <td>129.480000</td>\n",
       "      <td>96.06</td>\n",
       "      <td>177.3000</td>\n",
       "      <td>146.06</td>\n",
       "      <td>209.90</td>\n",
       "      <td>218.53</td>\n",
       "      <td>221.64</td>\n",
       "      <td>173.29</td>\n",
       "      <td>204.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-31</th>\n",
       "      <td>329.52</td>\n",
       "      <td>323.90</td>\n",
       "      <td>105.26</td>\n",
       "      <td>49.67</td>\n",
       "      <td>135.71</td>\n",
       "      <td>87.96</td>\n",
       "      <td>31.44</td>\n",
       "      <td>110.410000</td>\n",
       "      <td>150.62</td>\n",
       "      <td>158.56</td>\n",
       "      <td>...</td>\n",
       "      <td>142.50</td>\n",
       "      <td>128.590000</td>\n",
       "      <td>93.31</td>\n",
       "      <td>177.2500</td>\n",
       "      <td>146.87</td>\n",
       "      <td>205.75</td>\n",
       "      <td>220.65</td>\n",
       "      <td>221.03</td>\n",
       "      <td>169.24</td>\n",
       "      <td>205.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-01</th>\n",
       "      <td>330.94</td>\n",
       "      <td>316.40</td>\n",
       "      <td>103.63</td>\n",
       "      <td>49.74</td>\n",
       "      <td>137.58</td>\n",
       "      <td>88.59</td>\n",
       "      <td>31.13</td>\n",
       "      <td>110.930000</td>\n",
       "      <td>152.16</td>\n",
       "      <td>162.72</td>\n",
       "      <td>...</td>\n",
       "      <td>143.96</td>\n",
       "      <td>129.820000</td>\n",
       "      <td>94.28</td>\n",
       "      <td>180.0900</td>\n",
       "      <td>147.41</td>\n",
       "      <td>209.07</td>\n",
       "      <td>214.27</td>\n",
       "      <td>226.50</td>\n",
       "      <td>171.30</td>\n",
       "      <td>207.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-02</th>\n",
       "      <td>338.07</td>\n",
       "      <td>323.65</td>\n",
       "      <td>107.78</td>\n",
       "      <td>50.02</td>\n",
       "      <td>140.47</td>\n",
       "      <td>90.77</td>\n",
       "      <td>31.31</td>\n",
       "      <td>112.520000</td>\n",
       "      <td>156.26</td>\n",
       "      <td>168.56</td>\n",
       "      <td>...</td>\n",
       "      <td>146.52</td>\n",
       "      <td>132.420000</td>\n",
       "      <td>102.53</td>\n",
       "      <td>180.9500</td>\n",
       "      <td>148.82</td>\n",
       "      <td>226.63</td>\n",
       "      <td>218.07</td>\n",
       "      <td>228.79</td>\n",
       "      <td>175.13</td>\n",
       "      <td>213.32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1511 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               DIA    GS.N   NKE.N  CSCO.OQ   JPM.N   DIS.N  INTC.OQ  \\\n",
       "Date                                                                   \n",
       "2017-06-02  211.91  213.31   52.98    31.98   82.64  107.18    36.32   \n",
       "2017-06-05  211.86  213.99   53.01    31.76   82.79  106.52    36.34   \n",
       "2017-06-06  211.37  214.53   52.48    31.56   82.96  105.50    36.13   \n",
       "2017-06-07  211.72  215.78   53.23    31.61   83.91  105.92    36.26   \n",
       "2017-06-08  211.86  218.76   53.20    31.61   84.95  104.32    36.48   \n",
       "...            ...     ...     ...      ...     ...     ...      ...   \n",
       "2023-05-26  330.84  332.01  107.51    49.86  136.94   88.29    29.00   \n",
       "2023-05-30  330.52  330.83  106.52    50.17  137.46   87.82    29.99   \n",
       "2023-05-31  329.52  323.90  105.26    49.67  135.71   87.96    31.44   \n",
       "2023-06-01  330.94  316.40  103.63    49.74  137.58   88.59    31.13   \n",
       "2023-06-02  338.07  323.65  107.78    50.02  140.47   90.77    31.31   \n",
       "\n",
       "                 MRK.N   CVX.N   AXP.N  ...    PG.N       IBM.N   MMM.N  \\\n",
       "Date                                    ...                               \n",
       "2017-06-02   62.427347  103.11   78.49  ...   88.59  145.232686  206.70   \n",
       "2017-06-05   62.045937  103.19   78.97  ...   88.74  145.576545  206.22   \n",
       "2017-06-06   61.664526  104.17   78.85  ...   88.80  145.538339  205.41   \n",
       "2017-06-07   61.082876  103.77   79.81  ...   88.77  144.210661  205.01   \n",
       "2017-06-08   60.262843  104.00   79.95  ...   87.85  145.280444  205.94   \n",
       "...                ...     ...     ...  ...     ...         ...     ...   \n",
       "2023-05-26  111.070000  154.08  157.24  ...  145.40  128.890000   96.94   \n",
       "2023-05-30  109.170000  153.12  158.01  ...  143.18  129.480000   96.06   \n",
       "2023-05-31  110.410000  150.62  158.56  ...  142.50  128.590000   93.31   \n",
       "2023-06-01  110.930000  152.16  162.72  ...  143.96  129.820000   94.28   \n",
       "2023-06-02  112.520000  156.26  168.56  ...  146.52  132.420000  102.53   \n",
       "\n",
       "             AAPL.OQ   WMT.N   CAT.N  AMGN.OQ     V.N   TRV.N    BA.N  \n",
       "Date                                                                   \n",
       "2017-06-02   38.8625   79.62  105.95   159.15   96.15  125.15  190.23  \n",
       "2017-06-05   38.4825   80.26  105.20   160.22   96.55  125.38  188.95  \n",
       "2017-06-06   38.6125   78.93  104.55   159.53   95.79  124.03  186.75  \n",
       "2017-06-07   38.8425   79.15  103.51   161.66   96.09  123.50  188.10  \n",
       "2017-06-08   38.7475   78.93  105.01   162.65   96.09  123.78  189.93  \n",
       "...              ...     ...     ...      ...     ...     ...     ...  \n",
       "2023-05-26  175.4300  146.42  211.80   216.93  225.01  172.29  203.63  \n",
       "2023-05-30  177.3000  146.06  209.90   218.53  221.64  173.29  204.69  \n",
       "2023-05-31  177.2500  146.87  205.75   220.65  221.03  169.24  205.70  \n",
       "2023-06-01  180.0900  147.41  209.07   214.27  226.50  171.30  207.96  \n",
       "2023-06-02  180.9500  148.82  226.63   218.07  228.79  175.13  213.32  \n",
       "\n",
       "[1511 rows x 30 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f68cab43-6590-42b6-a768-0be5d8e21a98",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Daily Yield: 0.00014623\n"
     ]
    }
   ],
   "source": [
    "# 3-month T-bill annual yield\n",
    "annual_yield = 0.05482\n",
    "daily_yield = ((1 + annual_yield) ** (1 / 365)) - 1\n",
    "print(f'Daily Yield: {daily_yield:.8f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7217bb59-fd4d-4276-9eb7-5fb2a202b7aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Stocks based on significant Betas:\n",
      "['NKE.N', 'CSCO.OQ', 'DIS.N', 'INTC.OQ', 'HD.N', 'UNH.N', 'MSFT.OQ', 'HON.OQ', 'CRM.N', 'IBM.N', 'MMM.N', 'AAPL.OQ', 'CAT.N', 'V.N', 'TRV.N']\n"
     ]
    }
   ],
   "source": [
    "# Specify the time cutoff date as a string \n",
    "time_cutoff_date = '2022-01-01'\n",
    "\n",
    "# Calculate the excess daily returns for each stock by subtracting the estimated daily yield\n",
    "returns = df.pct_change().iloc[:, 1:].dropna() - daily_yield\n",
    "\n",
    "# Caculate market returns (DIA index)\n",
    "market_returns = df.pct_change().iloc[:, 0].dropna() - daily_yield\n",
    "\n",
    "# Calculate beta for each stock by fitting CAPM\n",
    "beta_values = {}\n",
    "p_values = {}\n",
    "for stock_symbol in returns.columns:\n",
    "    stock_returns = returns[stock_symbol]\n",
    "    \n",
    "    # Split the returns data based on the time cutoff date\n",
    "    stock_returns_train = stock_returns[stock_returns.index < time_cutoff_date]\n",
    "    market_returns_train = market_returns[market_returns.index < time_cutoff_date]\n",
    "\n",
    "\n",
    "    # Fit the OLS model (no need to add a constant term)\n",
    "    model = sm.OLS(stock_returns_train, market_returns_train).fit()\n",
    "    # Beta is the coefficient of the market returns variable\n",
    "    beta = model.params[0]\n",
    "    # Get the p-value for the beta coefficient\n",
    "    p_value = model.pvalues[0]\n",
    "    # Store beta and pvalues\n",
    "    beta_values[stock_symbol] = beta\n",
    "    p_values[stock_symbol] = p_value\n",
    "\n",
    "# Set thresholds for beta\n",
    "upper_threshold = 1.15\n",
    "lower_threshold = 0.85\n",
    "significance_level = 0.05 \n",
    "# Select stocks with beta values within the threshold range\n",
    "selected_stocks = [symbol for symbol, beta in beta_values.items() if lower_threshold <= beta <= upper_threshold and p_values[symbol] < significance_level]\n",
    "print(\"Selected Stocks based on significant Betas:\")\n",
    "print(selected_stocks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e33509-f970-4a7d-9c3c-ca7a97ccde8a",
   "metadata": {},
   "source": [
    "## Task 2 - Select a subset of constituents and fit a predictive linear model to forecast the index value (*40 points*)\n",
    "\n",
    "In this task, you will apply linear predictive modeling techniques to forecast the value of the DIA ETF on the DJIA index using the subset of its constituents you selected in the previous task. The goal is to build a predictive linear model that accurately estimates the future index return based on the historical data of selected constituent stocks. Note that to perform this predictive task, you have to prepare the data accordingly. Don't use the excess returns with respect to a daily risk-free rate for this task, but use the plain returns instead.\n",
    "\n",
    "The predictive linear regression equation to estimate the dependent variable \\(Y\\) at time \\(t+1\\) is represented as:\n",
    "\n",
    "$$ Y_{t+1} = \\beta_0 + \\beta_1 X_{1,t} + \\beta_2 X_{2,t} + \\ldots + \\beta_k X_{k,t} + \\varepsilon_{t} $$\n",
    "\n",
    "In this equation:\n",
    "\n",
    "- $Y_{t+1}$ represents the dependent variable at time $t+1$ that we want to predict. Note that the dependent variable is real-valued.\n",
    "- $\\beta_0$ is the intercept or constant term.\n",
    "- $\\beta_1, \\beta_2, \\ldots, \\beta_k$ are the $k$ coefficients for the independent variables $ X_{1,t}, X_{2,t}, \\ldots, X_{k,t} $ at time $t$. you can assume $k$ to be the number of selected stocks from the previous task. Note that the regressors are real-valued.\n",
    "- $\\varepsilon_{t}$ represents the error term at time $t$, capturing unexplained variation or noise in the dependent variable at that specific time.\n",
    "\n",
    "Before performing the linear regression modeling, remember to split the dataset into a training set and a test set. Use *2022-01-01* as a cutoff date, the same way you did in the previous task. Make sure the cutoff date will be included in the test set and not in the train set.\n",
    "\n",
    "Assess the performance of your predictive model using an appropriate evaluation metric for a regression problem like this one. Evaluate the model on the test set to ensure its predictive accuracy out-of-sample.\n",
    "\n",
    "**Grading Criteria**\n",
    "\n",
    "- **Data Preparation (15 points)**: Points will be awarded for preparing the data appropriately for the modeling task.\n",
    "\n",
    "- **Predictive Regression Model Building (20 points)**: Points will be awarded based on the correctness and completeness of the regression model built using selected stocks' returns and the index return.\n",
    "\n",
    "- **Model Evaluation (5 points)**: Points will be awarded based on the proper choice of evaluation metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9ae55fe-4910-418e-9056-6b36d33a3712",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.000146\n",
      "Root Mean Squared Error: 0.012065\n"
     ]
    }
   ],
   "source": [
    "# Extract the selected stock data and the index returns from price dataframe \n",
    "returns = df.pct_change().loc[:, ['DIA'] + selected_stocks].dropna()\n",
    "\n",
    "# Shift the target variable by one day to create target in order to predict tomorrow's index return\n",
    "returns['DIA_shifted'] = returns['DIA'].shift(-1)\n",
    "returns.dropna(inplace=True)  # Remove the last row with NaN target from the whole df\n",
    "\n",
    "# Define the features (selected stock returns) and target (future Dow Jones return)\n",
    "X = returns[selected_stocks]\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "y = returns['DIA_shifted']\n",
    "\n",
    "# Split the data based on the time cutoff\n",
    "X_train = X[X.index < time_cutoff_date]\n",
    "y_train = y[y.index < time_cutoff_date]\n",
    "X_test = X[X.index >= time_cutoff_date]\n",
    "y_test = y[y.index >= time_cutoff_date]\n",
    "\n",
    "# Create a linear regression model using statsmodels OLS\n",
    "model = sm.OLS(y_train, X_train).fit()\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = math.sqrt(mse)\n",
    "print(f'Mean Squared Error: {mse:.6f}')\n",
    "print(f'Root Mean Squared Error: {rmse:.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22aee638-53a5-41ce-8ac6-9c6f030870af",
   "metadata": {},
   "source": [
    "## Task 3 - Augment the Dataset with Bootstrapped Alphas and Fit again the Linear Predictive Models (40 points)\n",
    "\n",
    "In this task, we explore the concept of bootstrapped alphas and their role in predictive modeling. Bootstrapped alphas are used as proxy trading signals for real alphas that can be practically obtained. These signals are correlated with future returns and can play the role of good predictors in the predictive modeling process. Don't use the excess returns with respect to a daily risk-free rate for this task, but use the plain returns instead when you have to calculate the boostrapped alphas.\n",
    "\n",
    "We define bootstrapped alphas $\\alpha_t$ as per the formula below:\n",
    "\n",
    "$$\\alpha_{i,t} := \\rho_{\\text{boot}} r_{i,t+1} + \\sqrt{1 - \\rho_{\\text{boot}}^{2}} z_{i,t}$$\n",
    "\n",
    "where:\n",
    "- $r_{i,t+1}$ represents the next period return of the traded security $i$, which is given to you.\n",
    "- $z_{i,t} \\sim \\mathbb{N}(0,\\sigma^{2})$ is a randomly drawn scalar associated for each company $i$, which is not given and you have to sample. When sampling, ensure that each sampled vector is independent of the other since you have to draw samples for each company you will use as regressors. The number of companies stays the same that you used in the previous task and that you have selected by fitting the CAPM model in task 1.\n",
    "- $\\sigma^{2}_{i}$ is an estimate of the true conditional variance of the security $i$, which you have to calculate based on the given returns. Note that you have to calculate those variances on the train set only. Use the same cutoff applied in the previous task to define what the training set is.\n",
    "- $\\rho_{\\text{boot}} \\in [-1,1]$ is a correlation coefficient, which you have to set equal to 0.25.\n",
    "\n",
    "In this setting, the parameter $\\rho_{\\text{boot}}$ artificially regulates the strength of the trading signal you create. We remark that regressing the bootstrapped alpha $\\alpha_t$ on the future returns $r_{t+1}$ results in an $R^2$ equal to $\\rho^2$.\n",
    "\n",
    "The equation above formalizes the calculation of the boostrapped alpha for a single security while you will have more than one security. Try to make your calculations as efficient as possible by computing them simultaneously. It is possible by using calculations between pandas dataframe. Remember that $z_{i,t} \\sim \\mathcal{N}(0,\\sigma^{2}_{i})$ can be calculated as $z_{i,t} = \\sqrt{\\sigma^{2}_{i}}u_{i,t}$ where $u_{i,t} \\sim \\mathcal{N}(0,1)$. \n",
    "\n",
    "Once you calculate the boostrapped alphas, repeat the linear predictive forecasting exercise as in the previous task. This time you will use the boostrapped alphas as predictors, while you will keep the same target as before, the index returns. In other words, the target stays the same as in the previous task (future returns for DIA) by looking at the equation below. Still, the predictors change from the current returns of the constituents to the alpha bootstrap you have calculated.\n",
    "\n",
    "$$ Y_{t+1} = \\beta_0 + \\beta_1 X_{1,t} + \\beta_2 X_{2,t} + \\ldots + \\beta_k X_{k,t} + \\varepsilon_{t} $$\n",
    "\n",
    "To ensure reproducibility, please set the random seed to 42. Don't use another seed, and remember to set it. Avoiding to follow these guidelines will result in point deductions.\n",
    "\n",
    "**Motivation behind the task**\n",
    "\n",
    "In the dynamic and complex world of financial markets, predictive modeling is a potent tool to decipher underlying patterns and trends that govern security prices. Coming up with good predictors for a certain set of assets is a complicated task that is not necessarily the purpose of this assignment. The concept of bootstrapped alphas, as delineated in this exercise, emerges as a sophisticated method to engineer artificial trading signals that can potentially enhance the predictive power of financial models. It is equivalent to assuming that we have a way to predict the future returns of the index constituents. Look at the alpha bootstrap equation to understand why we are talking about future returns by looking at what the prices indicate.\n",
    "\n",
    "The utilization of bootstrapped alphas is grounded in the mathematical formulation provided, where the alpha ($\\alpha_{i,t}$) for a security $i$ at time $t$ is constructed using a combination of the next period return of the security ($r_{i,t+1}$) and a stochastic component ($z_{i,t}$) drawn from a normal distribution. This formulation allows for the incorporation of both deterministic and random elements, thereby mimicking the inherent uncertainty and volatility observed in financial markets.\n",
    "\n",
    "By setting the correlation coefficient ($\\rho_{\\text{boot}}$) to 0.25, we are essentially moderating the influence of the artificial trading signal, ensuring that it does not overwhelmingly dictate the behavior of the bootstrapped alphas. This parameter, therefore, serves as a tuning knob, allowing us to control the strength of the trading signal and, consequently, its predictive power. However, you have to keep this parameter fixed for this exercise, as indicated by the prompt.\n",
    "\n",
    "The subsequent step of employing these bootstrapped alphas as predictors in a linear predictive forecasting model is an exercise to highlight how well one can expect to forecast index returns, given a good way to predict future returns for the constituents. By replacing the current returns of the constituents with the calculated bootstrapped alphas, we are essentially enhancing the model with artificially generated yet statistically grounded signals that can potentially unveil deeper insights into the market dynamics.\n",
    "\n",
    "**Grading Criteria**\n",
    "\n",
    "- **Data Preparation (30 points)**: Points will be awarded for preparing the data appropriately for the modeling task.\n",
    "\n",
    "- **Predictive Regression Model Building (10 points)**: Points will be awarded based on the correctness and completeness of the regression model built using selected stocks' boostrapped alpha and the index return."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c291c79-a714-4f65-a413-c6b7b1c72e99",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.000084\n",
      "Root Mean Squared Error: 0.009146\n"
     ]
    }
   ],
   "source": [
    "rng = np.random.RandomState(42)\n",
    "conditional_variances = returns.loc[returns.index < time_cutoff_date,selected_stocks].var()\n",
    "random_vectors = pd.DataFrame(rng.normal(size=returns[selected_stocks].shape),columns=conditional_variances.index) * np.sqrt(conditional_variances)\n",
    "random_vectors.index = returns.index\n",
    "rho = 0.25\n",
    "# Compute the bootstrapped returns.\n",
    "bootstrapped_returns = rho * returns[selected_stocks].shift(-1) + np.sqrt(1 - rho**2) * random_vectors\n",
    "bootstrapped_returns.dropna(inplace=True)\n",
    "\n",
    "bootstrapped_returns['DIA_shifted'] = returns.iloc[:-1,-1]\n",
    "\n",
    "\n",
    "\n",
    "# Define the features (selected stock returns) and target (future Dow Jones return)\n",
    "X = bootstrapped_returns[selected_stocks]\n",
    "\n",
    "y = bootstrapped_returns['DIA_shifted']\n",
    "\n",
    "# Split the data based on the time cutoff\n",
    "X_train = X[X.index < time_cutoff_date]\n",
    "y_train = y[y.index < time_cutoff_date]\n",
    "X_test = X[X.index >= time_cutoff_date]\n",
    "y_test = y[y.index >= time_cutoff_date]\n",
    "\n",
    "# Create a linear regression model using statsmodels OLS\n",
    "model = sm.OLS(y_train, X_train).fit()\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = math.sqrt(mse)\n",
    "print(f'Mean Squared Error: {mse:.6f}')\n",
    "print(f'Root Mean Squared Error: {rmse:.6f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
